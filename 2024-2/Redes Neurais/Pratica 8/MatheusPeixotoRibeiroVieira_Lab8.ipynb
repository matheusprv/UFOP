{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 8 - BCC406\n",
        "\n",
        "## REDES NEURAIS E APRENDIZAGEM EM PROFUNDIDADE\n",
        "\n",
        "## *Word Embedding*\n",
        "\n",
        "### Prof. Eduardo e Prof. Pedro\n",
        "\n",
        "Objetivos:\n",
        "\n",
        "- Parte I : Uso de BoW para PLN\n",
        "\n",
        "- Parte II : Comparação com *word embedding* simples\n",
        "\n",
        "- Parte III: Visualizando as representações das palavras no espaço\n",
        "\n",
        "\n",
        "Data da entrega : 11/03\n",
        "\n",
        "- Complete o código (marcado com ToDo) e quando requisitado, escreva textos diretamente nos notebooks. Onde tiver *None*, substitua pelo seu código.\n",
        "- Execute todo notebook e salve tudo em um PDF **nomeado** como \"NomeSobrenome-Lab.pdf\"\n",
        "- Envie o PDF via google [FORM](https://forms.gle/gm1egpnfvTdQXYwp7)\n",
        "\n",
        "Este notebook é baseado em tensorflow e Keras."
      ],
      "metadata": {
        "id": "0EcNPTI11PXS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Representações de texto (*Bag-of-Words* vs. *Word Embeddings*) em NLP"
      ],
      "metadata": {
        "id": "h5OzALIdXDEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste exercício prático, vamos explorar duas abordagens diferentes para representar textos em português e treinar um modelo de classificação de texto simples. Usaremos um dataset desafiador de NLP em português – por exemplo, **[resenhas de filmes](https://https://drive.google.com/file/d/1KVIxGF6AVD6i43JPT0DBIZzYKJrBMoE5/view?usp=drive_link)** traduzidas para PT-BR, rotuladas como _positivas_ ou _negativas_.  O [dataset](https://https://drive.google.com/file/d/1KVIxGF6AVD6i43JPT0DBIZzYKJrBMoE5/view?usp=drive_link) contempla o review dado pelos usuários e o sentimento daquele review (positivo/negativo) com relação ao filme. O objetivo é, dado um review (ou resenha) em portugues, classificar o texto como positivo ou negativo.\n",
        "\n",
        "O exercício será dividido em duas etapas principais:  \n",
        "\n",
        "1. **Bag-of-Words + MLP:** Transformar os textos em vetores numéricos usando a técnica de **Bag-of-Words** (saco de palavras) baseada em frequência, e então treinar uma rede neural simples do tipo MLP (Perceptron Multicamadas) para classificar as resenhas.  \n",
        "2. **Word Embeddings + MLP:** Utilizar uma camada de **embedding** para converter palavras em vetores densos de dimensões menores, e treinar o mesmo modelo MLP, comparando os resultados com a abordagem de Bag-of-Words.  "
      ],
      "metadata": {
        "id": "19Vn3mjOXKYx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando as bibliotecas\n"
      ],
      "metadata": {
        "id": "DFqpYw56Xu1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui, faremos a importação de todas as bibliotecas que serão usadas nesta prática."
      ],
      "metadata": {
        "id": "qeN9qmjwXwq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, InputLayer, Dropout, BatchNormalization\n",
        "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "_jEVYCSEX0Zi"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparando os dados\n"
      ],
      "metadata": {
        "id": "htJoCXz9Xl1C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui assumiremos um dataset de **resenhas de filmes em português**, já categorizadas como sendo de sentimento **positivo** ou **negativo**.\n",
        "\n",
        "O dataset está disponível em um arquivo CSV, [na pasta da prática](https://https://drive.google.com/file/d/1KVIxGF6AVD6i43JPT0DBIZzYKJrBMoE5/view?usp=drive_link). Os passos a seguir demonstram como carregar e inspecionar os dados.\n",
        "\n",
        "O primeiro passo é fazer o download do arquivo.\n"
      ],
      "metadata": {
        "id": "EUDv4DoeXnxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1KVIxGF6AVD6i43JPT0DBIZzYKJrBMoE5"
      ],
      "metadata": {
        "id": "SH-rWHucX7Dx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b01ec26-c039-4e01-dc8c-adef7c907378"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1KVIxGF6AVD6i43JPT0DBIZzYKJrBMoE5\n",
            "From (redirected): https://drive.google.com/uc?id=1KVIxGF6AVD6i43JPT0DBIZzYKJrBMoE5&confirm=t&uuid=0595ac30-90fb-4e57-8b33-999aae39deaa\n",
            "To: /content/imdb-reviews-pt-br.csv\n",
            "100% 127M/127M [00:02<00:00, 55.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fazer a leitura do arquivo das resenhas com o pacote Pandas."
      ],
      "metadata": {
        "id": "vhG8tyZhboCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('imdb-reviews-pt-br.csv')"
      ],
      "metadata": {
        "id": "mid4i0OjXsz3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspecionando os dados."
      ],
      "metadata": {
        "id": "BKHSwumjbwIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar as primeiras linhas do dataset para entender sua estrutura\n",
        "print(f\"Número de exemplos: {len(df)}\")\n",
        "print(df.head(5))"
      ],
      "metadata": {
        "id": "TcGFPCPvbyGC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cff14e4b-31f1-4ca6-e82e-92d8752e6055"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de exemplos: 49459\n",
            "   id                                            text_en  \\\n",
            "0   1  Once again Mr. Costner has dragged out a movie...   \n",
            "1   2  This is an example of why the majority of acti...   \n",
            "2   3  First of all I hate those moronic rappers, who...   \n",
            "3   4  Not even the Beatles could write songs everyon...   \n",
            "4   5  Brass pictures movies is not a fitting word fo...   \n",
            "\n",
            "                                             text_pt sentiment  \n",
            "0  Mais uma vez, o Sr. Costner arrumou um filme p...       neg  \n",
            "1  Este é um exemplo do motivo pelo qual a maiori...       neg  \n",
            "2  Primeiro de tudo eu odeio esses raps imbecis, ...       neg  \n",
            "3  Nem mesmo os Beatles puderam escrever músicas ...       neg  \n",
            "4  Filmes de fotos de latão não é uma palavra apr...       neg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explicação:** O código acima lê o arquivo CSV contendo as resenhas. Substitua `'imdb-reviews-pt-br.csv'` pelo caminho adequado do seu dataset. Usamos `df.head(5)` para ver as primeiras 5 entradas e inspecionar as colunas. Provavelmente, o dataset terá uma coluna para o texto da resenha (por exemplo, `review_pt` ou `texto`) e outra para o rótulo de sentimento (por exemplo, `sentiment` indicando *positivo/negativo*).  \n",
        "\n",
        "O próximo passo é  extrair as colunas de texto e rótulo para listas (ou arrays) separados, o que facilitará o manuseio posteriormente."
      ],
      "metadata": {
        "id": "F1jpdfyEb6-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = df['text_pt'].astype(str).values    # convertendo para string por segurança\n",
        "labels = df['sentiment'].map({'neg': 0, 'pos': 1}).values"
      ],
      "metadata": {
        "id": "axMoJtlUc2Ok"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fazendo uma análise do que foi carregado."
      ],
      "metadata": {
        "id": "r3COjFW-c8bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total de textos:\", len(texts))\n",
        "print(\"Exemplo de texto:\", texts[0][:100], \"...\")  # imprime começo do primeiro texto\n",
        "print(\"Rótulo desse texto:\", labels[0])"
      ],
      "metadata": {
        "id": "sPaI_FtfdJO2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1a51e95-c3b7-4c9d-c44b-26a11c9ce83c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de textos: 49459\n",
            "Exemplo de texto: Mais uma vez, o Sr. Costner arrumou um filme por muito mais tempo do que o necessário. Além das terr ...\n",
            "Rótulo desse texto: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota:** Caso seu dataset tenha rótulos como \"positivo\"/\"negativo\" ou \"pos\"/\"neg\", converta-os para valores numéricos (e.g., 1 para positivo, 0 para negativo) conforme mostrado no comentário acima, pois isso facilita o treinamento do modelo.  \n",
        "\n",
        "Para simplificar o exercício e reduzir tempo de processamento (deixando-o _leve_), podemos **opcionalmente** trabalhar com uma amostra menor do dataset. Por exemplo, usar apenas 10.000 exemplos se o conjunto completo for muito grande."
      ],
      "metadata": {
        "id": "uMGa1pwVdStE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OPCIONAL: usar somente uma parte dos dados para treinamento mais rápido (por exemplo, 10000 primeiras linhas)\n",
        "df = df.sample(10000, random_state=42)  # amostra aleatória de 10000 exemplos"
      ],
      "metadata": {
        "id": "DCp9fwq8dY7G"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora que os dados estão carregados e prontos, vamos iniciar a **Parte 1: Bag-of-Words + MLP**."
      ],
      "metadata": {
        "id": "UHSxbBTZddOk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bag-of-Words + MLP"
      ],
      "metadata": {
        "id": "Cxk1b_kIddw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesta parte, vamos converter cada texto em uma representação numérica usando a técnica de **Bag-of-Words (BoW)** e depois treinar um modelo de rede neural simples para classificar os textos.  "
      ],
      "metadata": {
        "id": "8AA2xs37dhz3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### O que é Bag-of-Words?  "
      ],
      "metadata": {
        "id": "_hj0fLptdljA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bag-of-Words é uma das representações mais simples para texto. Nesta abordagem:  \n",
        "\n",
        "- **Vocabulário:** Primeiro definimos um vocabulário de palavras a partir do conjunto de textos de treino. O vocabulário pode ser todas as palavras distintas presentes ou um subconjunto (por exemplo, as N palavras mais frequentes).  \n",
        "- **Vetores de Frequência:** Cada texto é representado por um vetor de comprimento igual ao tamanho do vocabulário. Em cada posição do vetor colocamos a **frequência** (contagem) de ocorrência da palavra correspondente naquele texto. Por exemplo, se a palavra `filme` é a 5ª palavra do vocabulário, o elemento índice 5 do vetor conterá quantas vezes `filme` aparece na resenha.  \n",
        "- Por essa razão, é chamado de \"saco de palavras\": a ordem das palavras é **ignorada**. Apenas importa quantas vezes cada palavra apareceu. Em outras palavras, um documento é representado como um **multiconjunto** de palavras.  \n",
        "\n",
        "**Exemplo simples:**  \n",
        "Considere dois textos:  \n",
        "- Texto A: \"gostei do filme filme excelente\"  \n",
        "- Texto B: \"não gostei do filme\"  \n",
        "\n",
        "Suponha que o vocabulário construído seja: `[gostei, do, filme, excelente, não]`.  \n",
        "- Texto A teria representação BoW = `[1, 1, 2, 1, 0]` (1 ocorrência de \"gostei\", 1 de \"do\", 2 de \"filme\", 1 de \"excelente\", 0 de \"não\").  \n",
        "- Texto B teria representação BoW = `[1, 1, 1, 0, 1]` (1 \"gostei\", 1 \"do\", 1 \"filme\", 0 \"excelente\", 1 \"não\").  \n",
        "\n",
        "Observe que a posição de cada número corresponde a uma palavra do vocabulário.  "
      ],
      "metadata": {
        "id": "sFOB3MQCdnRr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Limitações do Bag-of-Words  "
      ],
      "metadata": {
        "id": "RSqwggEVdqfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embora seja fácil de entender e implementar, a representação Bag-of-Words tem algumas limitações importantes:  \n",
        "\n",
        "- **Alta Dimensionalidade:** O vetor resultante tem dimensão igual ao tamanho do vocabulário, que pode ser muito grande (milhares ou dezenas de milhares de palavras). Isso pode causar **esparsidade**, já que cada texto individual usa apenas uma fração do vocabulário (muitos zeros no vetor), exigindo mais memória e podendo dificultar o aprendizado do modelo.  \n",
        "- **Sem ordem ou contexto:** Como a ordem das palavras é ignorada, informações contextuais importantes se perdem. Por exemplo, \"não, gostei\" e \"gostei não\" teriam a mesma contagem de palavras, apesar de o significado ser diferente por causa da ordem. Bag-of-words não captura estruturas sintáticas ou a proximidade entre palavras.  \n",
        "- **Não captura o significado ou similaridade das palavras:** Cada palavra é uma dimensão independente. Palavras como **\"ótimo\"** e **\"excelente\"** serão representadas em dimensões diferentes, mesmo tendo significado semelhante. O modelo precisaria aprender do zero que ambas indicam algo positivo, pois BoW não fornece nenhuma noção de que essas palavras estão relacionadas. Em resumo, BoW trata palavras como tokens independentes sem nenhuma relação intrínseca.  \n",
        "\n",
        "Apesar dessas limitações, Bag-of-Words costuma funcionar bem em tarefas simples e é um bom ponto de partida para entendermos representações de texto.  \n"
      ],
      "metadata": {
        "id": "2afUuDisdsSa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementação Bag-of-Words + MLP"
      ],
      "metadata": {
        "id": "MkDB2cQpdy4K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora vamos colocar em prática: primeiro transformando nossos textos em vetores de frequência (BoW), depois treinando um modelo de classificação simples.  \n",
        "\n"
      ],
      "metadata": {
        "id": "19k62DMzd1bE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1. Vetorização com Bag-of-Words:**  "
      ],
      "metadata": {
        "id": "xyTreARmd9bD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Usaremos a biblioteca **scikit-learn** ou utilitários do Keras para converter a lista de textos em uma matriz de características. Uma forma prática é usar `CountVectorizer` do scikit-learn, que faz todo o processo de: tokenizar os textos, construir o vocabulário e contar frequências.  \n",
        "\n",
        "Vamos limitar o tamanho do vocabulário para, digamos, as 5000 palavras mais frequentes, a fim de tornar a representação mais leve (ignorando palavras muito raras, que pouco contribuem e só aumentam a dimensão).  "
      ],
      "metadata": {
        "id": "uBkWdB_Jd8L7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 5000  # tamanho máximo do vocabulário\n",
        "vectorizer = CountVectorizer(max_features=max_features, stop_words=None)  # podemos adicionar stop_words='portuguese' se quisermos remover stopwords"
      ],
      "metadata": {
        "id": "lJWkIMTBeoAy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com os parâmetros definidos, é possível treinar o vetorizaor nos textos de treino e transformar os textos em matriz BoW, onde a matriz resultante será esparsa e com dimensão `(n_amostras, max_features)`"
      ],
      "metadata": {
        "id": "25bDCdvuewOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_bow = vectorizer.fit_transform(texts)\n",
        "\n",
        "print(\"Formato da matriz BoW:\", X_bow.shape)"
      ],
      "metadata": {
        "id": "S3LHNkfsewny",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e48ec516-f628-463e-8f24-9233ed17ed72"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formato da matriz BoW: (49459, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Após essa etapa, `X_bow` é uma matriz esparsa onde cada linha corresponde a um texto, e cada coluna a uma palavra do vocabulário (de tamanho até 5000). O valor em `X_bow[i,j]` é a contagem da j-ésima palavra do vocabulário no i-ésimo texto.  \n",
        "\n",
        "Podemos inspecionar alguns exemplos para ter certeza de que faz sentido:  "
      ],
      "metadata": {
        "id": "TcPHgEMzfGgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ver algumas palavras do vocabulário\n",
        "print(\"Algumas palavras do vocabulário:\", vectorizer.get_feature_names_out()[:100])\n",
        "\n",
        "# Mostrar vetor BoW da primeira resenha (convertido para array denso apenas para visualizar)\n",
        "print(\"Vetor BoW da primeira resenha:\\n\", X_bow[0].toarray())\n",
        "\n",
        "# (Nota: a maioria dos elementos será zero; podemos também somar para ver o total de palavras contadas)\n",
        "print(\"Total de palavras na primeira resenha:\", int(X_bow[0].sum()))"
      ],
      "metadata": {
        "id": "nAyuuTN-fHM_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e12715d0-6d92-457c-fe36-46ae8e8694e1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Algumas palavras do vocabulário: ['00' '000' '10' '100' '11' '12' '13' '14' '15' '16' '17' '18' '19' '1930'\n",
            " '1940' '1950' '1960' '1970' '1972' '1979' '1980' '1990' '1995' '1996'\n",
            " '1999' '20' '2000' '2001' '2002' '2003' '2004' '2005' '2006' '2007' '21'\n",
            " '24' '25' '30' '35' '40' '45' '50' '60' '70' '80' '90' '99' 'abaixo'\n",
            " 'abandonado' 'abc' 'aberta' 'aberto' 'abertura' 'abordagem' 'aborrecido'\n",
            " 'abre' 'abrir' 'absoluta' 'absolutamente' 'absoluto' 'absurda' 'absurdo'\n",
            " 'abundância' 'abuso' 'acaba' 'acabado' 'acabam' 'acabar' 'acabaram'\n",
            " 'acabei' 'acabou' 'academia' 'acampamento' 'acaso' 'aceita' 'aceitar'\n",
            " 'aceitável' 'acha' 'acham' 'achar' 'achava' 'achei' 'acho' 'achou'\n",
            " 'acidentalmente' 'acidente' 'acima' 'acompanha' 'acompanhar' 'acontece'\n",
            " 'acontecem' 'acontecendo' 'acontecer' 'aconteceu' 'acontecido'\n",
            " 'acontecimentos' 'aconteça' 'acorda' 'acordado' 'acordo']\n",
            "Vetor BoW da primeira resenha:\n",
            " [[0 0 0 ... 1 0 0]]\n",
            "Total de palavras na primeira resenha: 132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2. Dividir dados em treino e teste:**  "
      ],
      "metadata": {
        "id": "wllWW4cffPEO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de treinar o modelo, é importante separar uma parte dos dados para teste (avaliação). Assim podemos medir o desempenho em dados não vistos durante o treino. Vamos dividir, por exemplo, 80% para treino e 20% para teste.  "
      ],
      "metadata": {
        "id": "q4hFM4zqfQm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_bow, X_test_bow, y_train, y_test = train_test_split(\n",
        "    X_bow, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Conjunto de treino - textos:\", X_train_bow.shape, \" rótulos:\", y_train.shape)\n",
        "print(\"Conjunto de teste - textos:\", X_test_bow.shape, \" rótulos:\", y_test.shape)"
      ],
      "metadata": {
        "id": "ManN9gVifSn1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c729e02-5ff7-4f18-fe15-22a5de0ce7a0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conjunto de treino - textos: (39567, 5000)  rótulos: (39567,)\n",
            "Conjunto de teste - textos: (9892, 5000)  rótulos: (9892,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3. Definir e treinar o modelo MLP:**"
      ],
      "metadata": {
        "id": "_B5zpqAnfYRp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usaremos uma rede neural simples (MLP) para classificação binária (positivo/negativo). Como entrada, o MLP receberá os vetores BoW de cada texto. Nossa arquitetura será simples para ser rápida de treinar: por exemplo, uma camada densa escondida com algumas unidades e ReLU, seguida de uma camada de saída com ativação sigmoide (para prever a probabilidade de classe positiva).  \n",
        "\n",
        "Detalhes:  \n",
        "- Input dimension = tamanho do vocabulário (5000 características neste caso).  \n",
        "- Uma camada oculta, digamos com 16 ou 32 neurônios, ativação ReLU. (Poderia ser mais complexa, mas manteremos simples).  \n",
        "- Saída: 1 neurônio com ativação sigmoide (porque é binário).  \n",
        "- Função de perda: `binary_crossentropy` (entropia cruzada binária).  \n",
        "- Otimizador: por exemplo, `adam`.  \n",
        "- Métrica: acurácia (para acompanhar desempenho).  \n",
        "\n",
        "Vamos construir o modelo usando Keras (TensorFlow):  "
      ],
      "metadata": {
        "id": "qrpcjTS9fay3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construir modelo MLP para Bag-of-Words\n",
        "model_bow = Sequential()\n",
        "model_bow.add(Dense(16, activation='relu', input_shape=(X_train_bow.shape[1],)))\n",
        "model_bow.add(Dense(1, activation='sigmoid'))  # saída binária\n",
        "\n",
        "model_bow.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_bow.summary()"
      ],
      "metadata": {
        "id": "fBC89i4pfbaZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "273aa9a8-93b4-4c2e-c7df-24ead770bee5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │          \u001b[38;5;34m80,016\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">80,016</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m80,033\u001b[0m (312.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">80,033</span> (312.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m80,033\u001b[0m (312.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">80,033</span> (312.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observação:** A camada de entrada (`Dense(16, ..., input_shape=(X_train_bow.shape[1],))`) espera um vetor de tamanho 5000 (no nosso caso) para cada exemplo. Esse será exatamente o vetor BoW de cada texto.  \n",
        "\n",
        "Agora treinamos o modelo por algumas épocas (epochs). Como o dataset pode ser grande, comece com um número pequeno de épocas, por exemplo 3 a 5, e veja o resultado. (Em um problema real, poderíamos treinar mais, mas queremos um experimento rápido.)  "
      ],
      "metadata": {
        "id": "2F3OuGbzffhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_bow = model_bow.fit(X_train_bow.toarray(),\n",
        "                            np.asarray([0 if x == 'neg' else 1 for x in y_train]),  # convertendo X_train de esparso para denso para treinar\n",
        "                            epochs=5,\n",
        "                            batch_size=32,\n",
        "                            validation_data=(X_test_bow.toarray(), y_test))"
      ],
      "metadata": {
        "id": "D8LdbZy5fokU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33479f29-641b-4c49-e212-c376811f4ec2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9946 - loss: 0.0310 - val_accuracy: 0.4907 - val_loss: 11.6252\n",
            "Epoch 2/5\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7301e-04 - val_accuracy: 0.4907 - val_loss: 14.9292\n",
            "Epoch 3/5\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1146e-04 - val_accuracy: 0.4907 - val_loss: 17.3630\n",
            "Epoch 4/5\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.7957e-05 - val_accuracy: 0.4907 - val_loss: 19.6177\n",
            "Epoch 5/5\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.7896e-05 - val_accuracy: 0.4907 - val_loss: 21.7652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota:** Aqui convertemos explicitamente `X_train_bow` e `X_test_bow` para arrays densos (`toarray()`), porque o Keras requer entrada densa em NP array. Isso é viável se o vocabulário não for muito grande. Com `max_features=5000`, a matriz densificada ainda é gerenciável em termos de memória. Se o vocabulário fosse muito maior, poderíamos usar métodos mais avançados ou treinar com o próprio TensorFlow tfidf layer etc., mas não vamos complicar neste exercício inicial.  \n",
        "\n",
        "Durante o treinamento, observe a *loss* (função de perda) e *accuracy* tanto do treino quanto da validação a cada época. Após treinar, vamos avaliar a performance final no conjunto de teste:  \n"
      ],
      "metadata": {
        "id": "E8RLk-E3fsyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_bow, acc_bow = model_bow.evaluate(X_test_bow.toarray(), y_test, verbose=0)\n",
        "print(f\"Acurácia no conjunto de teste (BoW + MLP): {acc_bow:.4f}\")"
      ],
      "metadata": {
        "id": "tXra_mcthr4L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7cf3882-b931-4650-ba85-c434500bddac"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia no conjunto de teste (BoW + MLP): 0.4907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Também podemos inspecionar algumas previsões do modelo para ver se ele faz sentido (lembrando que 1 são para as classes 'pos' e 0 (zero), 'neg'):"
      ],
      "metadata": {
        "id": "-V1VdWFjhwuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazer previsões em alguns exemplos de teste\n",
        "pred_probs = model_bow.predict(X_test_bow.toarray()[:5])  # probabilidades previstas para 5 exemplos\n",
        "pred_classes = (pred_probs > 0.5).astype(int)             # classifica como 1 se prob > 0.5, senão 0\n",
        "\n",
        "print(\"Probabilidades previstas:\", pred_probs[:,0])\n",
        "print(\"Classes previstas:\", pred_classes[:,0])\n",
        "print(\"Classes verdadeiras :\", y_test[:5])"
      ],
      "metadata": {
        "id": "FuLUhJ9phyxr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2daa2a3a-8985-44db-9c80-7a95470d8fec"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
            "Probabilidades previstas: [1.         1.         1.         0.99998784 1.        ]\n",
            "Classes previstas: [1 1 1 1 1]\n",
            "Classes verdadeiras : [1 0 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Isso imprime as probabilidades que o modelo atribuiu à classe positiva e as classes finais comparadas com as verdadeiras para os primeiros 5 textos de teste.  \n",
        "\n",
        "**Discussão dos resultados (Parte 1):** Após o treinamento, devemos obter uma certa acurácia de teste (por exemplo, algo em torno de 80% a 85% para um bom modelo de sentimento com dados do IMDb traduzido, embora esse número possa variar). É importante notar:  \n",
        "\n",
        "- Se o desempenho não estiver tão bom, lembre-se das limitações do BoW. Palavras como *\"bom\"* e *\"ótimo\"* foram tratadas de forma independente. Talvez o modelo nunca viu a palavra *\"espetacular\"* no treino mas viu *\"excelente\"*, e não consegue generalizar bem, pois no BoW não há relação entre essas expressões de sentimento positivo.  \n",
        "- O modelo também não considera a ordem, então frases negativas com negações podem confundir (por exemplo, \"*não gostei*\" versus \"*gostei*\"). Podemos melhorar isso futuramente com processamento de texto (como remover ou tratar \"*não*\") ou usando métodos mais avançados.  \n",
        "- Apesar de simples, este BoW+MLP já consegue capturar padrões básicos: palavras positivas contribuem para aumentar a probabilidade de classe positiva e vice-versa para negativas, porque durante o treinamento os pesos da rede associam essas colunas (palavras) ao efeito no resultado.  \n"
      ],
      "metadata": {
        "id": "MpKFDwUMiAje"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Embeddings + MLP"
      ],
      "metadata": {
        "id": "fib4N9iyiFBj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora que entendemos e implementamos o modelo usando Bag-of-Words, vamos melhorar a representação do texto usando **Word Embeddings** (embeddings de palavras). Em vez de representarmos cada palavra como uma dimensão separada no vetor (como no BoW), vamos representar cada palavra por um vetor **denso** de características, aprendendo essas representações automaticamente durante o treinamento.  \n"
      ],
      "metadata": {
        "id": "kkDUnryBiHFK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introdução a Word Embeddings"
      ],
      "metadata": {
        "id": "crPdb_CEiI1X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word embeddings** são uma forma de representar palavras em um espaço vetorial de dimensionalidade reduzida (geralmente dezenas ou poucas centenas de dimensões), de tal forma que palavras com significados ou contextos semelhantes fiquem com vetores \"próximos\" uns dos outros nesse espaço.  \n",
        "\n",
        "Em vez de vetores esparsos enormes (como one-hot encoding ou BoW, onde \"excelente\" poderia ser `[0,0,...,1,...0]` com dimensão de milhares), um embedding aprende um vetor compacto, por exemplo, de dimensão 50 ou 100, onde cada elemento do vetor não é mais binário, mas sim um valor real que contribui para descrever algum aspecto do significado ou uso daquela palavra.  \n",
        "\n",
        "**Como funciona na prática?** No contexto de redes neurais, uma camada de embedding é essencialmente uma matriz de pesos que mapeia cada índice de palavra do vocabulário para um vetor denso. No começo do treino, esses vetores podem ser inicializados aleatoriamente. Durante o treinamento (por exemplo, de um modelo de classificação), a rede ajusta os valores desses vetores de forma que a representação das palavras ajude a resolver a tarefa final.  \n",
        "\n",
        "Benefícios dos embeddings sobre BoW:  \n",
        "\n",
        "- **Dimensionalidade menor:** Podemos escolher o tamanho do vetor de embedding (por exemplo, 50) independentemente do tamanho do vocabulário (que poderia ser 5000). Assim, cada palavra é representada por 50 números em vez de uma posição fixa em um vetor de 5000 dimensões. Isso reduz drasticamente a dimensionalidade da entrada do modelo e tende a diminuir a esparsidade.  \n",
        "- **Captura semântica:** Palavras que aparecem em contextos semelhantes terão vetores parecidos. Por exemplo, pode acontecer de o embedding de *\"excelente\"* ficar próximo do embedding de *\"ótimo\"*, porque ambas aparecem em contextos de elogio em várias resenhas. Assim, mesmo que uma palavra específica não apareça no conjunto de treino, o modelo pode generalizar melhor se palavras sinônimas apareceram.  \n",
        "- **Ordem e contexto local:** Embora a simples camada de embedding em si não capture a ordem global do texto (isso exigiria arquiteturas como redes recorrentes ou transformers), podemos, no mínimo, usar a sequência de embeddings para extrair informações. No nosso caso, faremos uma simplificação pegando uma média ou outra agregação dos embeddings das palavras do texto, mas poderíamos também ir além com modelos sequenciais. De qualquer forma, usar embeddings prepara o terreno para métodos mais avançados e já é um passo além do BoW.  \n",
        "\n",
        "Em resumo, os **embeddings aprendem representações distribuídas**: cada dimensão do vetor de embedding não representa uma palavra específica (ao contrário do BoW), mas captura alguma característica latente que pode ser compartilhada entre várias palavras.  "
      ],
      "metadata": {
        "id": "1BT1tNviiMc-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementação Word Embeddings + MLP"
      ],
      "metadata": {
        "id": "KlGxyDK1iOxD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos refazer o processo de classificação das resenhas, mas agora utilizando uma camada de embedding treinável.  "
      ],
      "metadata": {
        "id": "yIN5BWShiQMU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1. Tokenização e preparação das sequências:**  "
      ],
      "metadata": {
        "id": "N9snnqdxiSxp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Para usar embeddings, precisamos primeiro converter cada texto em uma sequência de índices inteiros que representem as palavras. Ou seja, construiremos um vocabulário (como antes) mas em vez de uma matriz de contagens, vamos representar cada frase como uma sequência de números.  \n",
        "\n",
        "Podemos reutilizar o objeto `CountVectorizer`? Não diretamente para sequências. Em vez disso, usaremos a classe `Tokenizer` do Keras (ou `TextVectorization` do TensorFlow 2.x). O Tokenizer nos permite mapear cada palavra a um índice e também transformar textos em sequências de índices.  \n",
        "\n",
        "Vamos configurar um Tokenizer para considerar o mesmo tamanho de vocabulário (por exemplo, top 5000 palavras) e então gerar sequências:  "
      ],
      "metadata": {
        "id": "Z8aKbjLQiYyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir um tokenizer para criar índices para as palavras (mesmo tamanho de vocabulário para comparação justa)\n",
        "max_words = 5000  # tamanho do vocabulário\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
        "# oov_token opcional para indicar token \"Out-Of-Vocabulary\" caso palavras fora dos 5000 apareçam\n",
        "\n",
        "# Treinar o tokenizer nos textos de treino (ajusta o vocabulário)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "# Converter textos em sequências de índices\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "print(\"Exemplo de sequência (antes do padding):\", sequences[0][:10])  # primeiros 10 tokens do primeiro texto"
      ],
      "metadata": {
        "id": "4kceViiJibFu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b2341c0-f9c2-48f4-b0a1-da7236338ee3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exemplo de sequência (antes do padding): [25, 12, 75, 5, 568, 1, 1, 7, 9, 21]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cada sequência agora é uma lista de números inteiros, onde cada inteiro corresponde a uma palavra específica do vocabulário. Porém, essas sequências têm comprimentos variáveis (uma resenha pode ter 100 palavras, outra 200, etc.). Redes neurais esperam entradas de tamanho fixo, então precisamos **padronizar** o comprimento das sequências.  \n",
        "\n",
        "Uma técnica comum é **padding**, ou seja, preenchimento: definimos um tamanho máximo de sequência e preenchemos com zeros (ou truncamos) as sequências para todas ficarem com o mesmo comprimento.  \n",
        "\n",
        "Vamos definir um `maxlen` (por exemplo, talvez 100 ou 200 palavras por resenha, dependendo da distribuição do tamanho das resenhas. Para segurança, podemos pegar algo como 100 palavras para não estourar memória).  \n"
      ],
      "metadata": {
        "id": "zWiW5abmib5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir um tamanho máximo para as sequências (número máximo de palavras consideradas de cada texto)\n",
        "maxlen = 100  # ajustável; aqui cada texto será representado pelos primeiros 100 tokens (ou completado com pad se tiver menos)\n",
        "\n",
        "# Aplicar padding nas sequências para que todas tenham comprimento maxlen\n",
        "X_seq = pad_sequences(sequences, maxlen=maxlen, padding='post', truncating='post')\n",
        "\n",
        "print(\"Formato da matriz de sequências com padding:\", X_seq.shape)\n",
        "print(\"Sequência de exemplo (apos padding):\", X_seq[0])"
      ],
      "metadata": {
        "id": "_SLs1MhlifhL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07df2a21-3eab-4665-ad27-abb98f867372"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formato da matriz de sequências com padding: (49459, 100)\n",
            "Sequência de exemplo (apos padding): [  25   12   75    5  568    1    1    7    9   21   27   25   71   15\n",
            "    3    5 1376  156   69 1006 1516    2 3299   22 1700   69  666   56\n",
            "   27 1245   14  171   10   55    1   16  206   34   79    6  205    2\n",
            "  174   46 2090   22 4447    4    5  109    1    8 3849  599   22  370\n",
            "    4   77 2040   80   27   25  398   43   14   10   55 3107    5  109\n",
            "   16    5  268    1   84 1796    8   27 2649    4    1    1    1    5\n",
            "  361    8    3   23  868   18    7  603    3 1541    3    8   65   15\n",
            "    3   73]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora `X_seq` é uma matriz de shape `(n_amostras, maxlen)`, onde cada linha é a sequência de índices de palavras de um texto, com zeros no fim se o texto original tinha menos que `maxlen` palavras (ou truncado se tinha mais).  \n",
        "\n",
        "**2. Dividir em treino e teste (novamente):**  \n",
        "\n",
        "Precisamos dividir também essas sequências em treino e teste, de forma consistente com o que fizemos antes. (Se quisermos comparar resultados, é bom que a divisão de treino/teste seja a mesma da parte 1; para isso, podemos usar o mesmo `train_test_split` passando os mesmos índices, ou simplesmente dividir `X_seq` e `labels` novamente com o mesmo random_state.)  \n"
      ],
      "metadata": {
        "id": "SyHHiDXiikk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_seq, X_test_seq, y_train_seq, y_test_seq = train_test_split(\n",
        "    X_seq, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Treino seq shape:\", X_train_seq.shape, \"Teste seq shape:\", X_test_seq.shape)"
      ],
      "metadata": {
        "id": "3agpvqZuilMZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2615fa64-e02d-4673-cd61-12829fe2d28e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treino seq shape: (39567, 100) Teste seq shape: (9892, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3. Definir o modelo com camada de Embedding:**"
      ],
      "metadata": {
        "id": "QE64ZeRyiotb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora vem a diferença crucial: na entrada da rede, em vez de receber um vetor de contagens de tamanho fixo para cada texto, vamos passar a sequência de índices para uma **Embedding Layer**. Essa camada atuará como uma tabela de look-up que mapeia cada índice de palavra para um vetor denso (que será treinado).  \n",
        "\n",
        "Configurações para a camada de embedding:  \n",
        "- `input_dim = max_words` (tamanho do vocabulário, ou seja, índice máximo + 1).  \n",
        "- `output_dim = dimensão do embedding` (é um hiperparâmetro; podemos escolher, por exemplo, 50 ou 100). Dimensões típicas variam de 50 a 300; vamos usar 50 para ser leve.  \n",
        "- `input_length = maxlen` (o comprimento das sequências que estamos passando).  \n",
        "\n",
        "Depois da camada de embedding, obteremos uma saída de tamanho `(batch_size, maxlen, output_dim)` – essencialmente uma matriz de embeddings para cada palavra da sequência. Precisamos então combinar essas informações para passá-las à parte densa do MLP. Existem algumas estratégias simples que podemos usar sem complicar muito (já que não estamos implementando RNN ou Transformer aqui):  \n",
        "\n",
        "- **Usar uma camada de Pooling (GlobalAveragePooling1D ou GlobalMaxPooling1D):** Isso reduzirá a sequência de embeddings a um único vetor fixo, agregando as informações de cada palavra. Por exemplo, o GlobalAveragePooling1D faz a média vetor elemento a elemento de todos os embeddings da sequência, resultando em um vetor de mesma dimensão do embedding. Essa média representa aproximadamente o \"significado médio\" das palavras do texto. O GlobalMaxPooling1D pegaria o valor máximo em cada dimensão dentre todas as palavras (capturando talvez o aspecto mais forte presente).  \n",
        "- **Ou achatar (Flatten) a sequência de embeddings:** concatenando todos os embeddings em um vetor gigantesco de tamanho `maxlen * output_dim`. Porém, isso pode gerar um vetor muito grande (no nosso caso seria 100 * 50 = 5000, coincidentemente igual ao BoW de 5000 palavras). Flatten perde a invariância de posição (a rede teria que aprender quais posições do flatten importam, o que é como aprender ordem, o que seria mais complexo). Para simplificar, preferiremos um pooling global, que é eficaz e mantém o número de features baixo.  \n",
        "\n",
        "Vamos então montar o modelo:  "
      ],
      "metadata": {
        "id": "bm5UxDN7ipo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 50\n",
        "\n",
        "model_emb = Sequential()\n",
        "model_emb.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=maxlen))\n",
        "model_emb.add(GlobalAveragePooling1D())\n",
        "model_emb.add(Dense(16, activation='relu'))\n",
        "model_emb.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_emb.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_emb.summary()"
      ],
      "metadata": {
        "id": "MaVeQaAsirsk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "99233731-f011-482a-8e6f-75548de0ca7a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d             │ ?                           │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d             │ ?                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos explicar a arquitetura:  \n",
        "- A primeira camada `Embedding` transforma a sequência de 100 índices em uma sequência de 100 vetores de dimensão 50. (Parâmetros: `input_dim=5000`, `output_dim=50`, `input_length=100`.)  \n",
        "- `GlobalAveragePooling1D` toma a média dos 100 vetores de dimensão 50, resultando em **um vetor de dimensão 50** que é a entrada para a próxima camada. (Assim, reduzimos a sequência de embeddings a uma única representação fixa do texto.)  \n",
        "- Depois vem uma camada densa oculta com 16 neurônios (e ReLU), igual à usada no modelo anterior.  \n",
        "- Camada de saída sigmoide para prever positivo/negativo.  \n",
        "\n",
        "O número total de parâmetros na camada de embedding é `input_dim * output_dim` (5000 * 50 = 250k parâmetros), o que pode parecer muito, mas note que muitos deles podem não ser atualizados muito se algumas palavras não aparecerem. Ainda assim, 250k é manejável. A vantagem é que esses parâmetros **substituem** a necessidade de ter 5000 entradas distintas no vetor de input – aqui, 50 números *aprendidos* acabam codificando informações das 5000 palavras de forma distribuída.  "
      ],
      "metadata": {
        "id": "nCfGNrRHivg3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **4. Treinar o modelo de Embedding:**  "
      ],
      "metadata": {
        "id": "QrQFjbc6ixHr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora vamos treinar este modelo da mesma forma que antes.  "
      ],
      "metadata": {
        "id": "uv881VpQiyHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_seq, X_train_seq.shape)\n",
        "print(y_train_seq, y_train_seq.shape)"
      ],
      "metadata": {
        "id": "9MkLXGPzjHVx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14c92dd2-3a23-462e-9e6e-5201c9a17e14"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  28    9    8 ...    0    0    0]\n",
            " [  19    1 1864 ...  455  300  160]\n",
            " [ 817   96    3 ...    0    0    0]\n",
            " ...\n",
            " [  65  166  218 ...  118   70   37]\n",
            " [  14    1  229 ...   16    5 1072]\n",
            " [ 844  213 2773 ...  169  320 1404]] (39567, 100)\n",
            "[0 0 0 ... 1 0 1] (39567,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_emb = model_emb.fit(X_train_seq,\n",
        "                            y_train_seq,\n",
        "                            epochs=10,\n",
        "                            batch_size=32,\n",
        "                            validation_data=(X_test_seq, y_test_seq))"
      ],
      "metadata": {
        "id": "qoUbe_6Ti0hW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d7c3f9a-4e0b-4467-954f-c7c642cbaeed"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.6870 - loss: 0.5718 - val_accuracy: 0.8161 - val_loss: 0.4025\n",
            "Epoch 2/10\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8440 - loss: 0.3558 - val_accuracy: 0.8201 - val_loss: 0.3998\n",
            "Epoch 3/10\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8549 - loss: 0.3297 - val_accuracy: 0.8215 - val_loss: 0.4069\n",
            "Epoch 4/10\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8654 - loss: 0.3165 - val_accuracy: 0.8116 - val_loss: 0.4265\n",
            "Epoch 5/10\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8644 - loss: 0.3103 - val_accuracy: 0.8192 - val_loss: 0.4143\n",
            "Epoch 6/10\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8674 - loss: 0.3086 - val_accuracy: 0.8175 - val_loss: 0.4164\n",
            "Epoch 7/10\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8684 - loss: 0.3092 - val_accuracy: 0.8126 - val_loss: 0.4228\n",
            "Epoch 8/10\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8682 - loss: 0.3040 - val_accuracy: 0.8161 - val_loss: 0.4243\n",
            "Epoch 9/10\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8706 - loss: 0.3038 - val_accuracy: 0.8139 - val_loss: 0.4301\n",
            "Epoch 10/10\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8754 - loss: 0.2928 - val_accuracy: 0.8126 - val_loss: 0.4318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note que agora passamos diretamente `X_train_seq` (que é uma matriz de inteiros) ao modelo – a primeira camada do modelo (Embedding) cuidará de converter inteiros em vetores automaticamente durante o treinamento. Não precisamos transformar nada manualmente além do padding feito anteriormente.  \n",
        "\n",
        "Após o treinamento, avaliamos o modelo no conjunto de teste:"
      ],
      "metadata": {
        "id": "ICzzQJsSi2Kc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_emb, acc_emb = model_emb.evaluate(X_test_seq, y_test_seq, verbose=0)\n",
        "print(f\"Acurácia no conjunto de teste (Embeddings + MLP): {acc_emb:.4f}\")\n"
      ],
      "metadata": {
        "id": "24exAHg6jFTM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5acb269-7c89-4c8f-efb7-2cbb7af51a56"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia no conjunto de teste (Embeddings + MLP): 0.8126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos também comparar as performances:  "
      ],
      "metadata": {
        "id": "vpByUtzljdrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Acurácia BoW: {acc_bow:.4f} vs Acurácia Embedding: {acc_emb:.4f}\")"
      ],
      "metadata": {
        "id": "xjCQ19DAjfPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "807c80fa-c697-4199-cd1d-b935fc531983"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia BoW: 0.4907 vs Acurácia Embedding: 0.8126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "E verificar novamente algumas previsões para ver se batem com as expectativas:  "
      ],
      "metadata": {
        "id": "p7LNZl32jhnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_probs_emb = model_emb.predict(X_test_seq[:5])\n",
        "pred_classes_emb = (pred_probs_emb > 0.5).astype(int)\n",
        "\n",
        "print(\"Classes previstas (BoW)     :\", pred_classes[:,0])\n",
        "print(\"Classes previstas (Embedd.):\", pred_classes_emb[:,0])\n",
        "print(\"Classes verdadeiras         :\", y_test_seq[:5])"
      ],
      "metadata": {
        "id": "bfKBjRfhjjUa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16c97f77-9746-4b79-8cf0-d703c8280e28"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step\n",
            "Classes previstas (BoW)     : [1 1 1 1 1]\n",
            "Classes previstas (Embedd.): [0 0 0 0 1]\n",
            "Classes verdadeiras         : [1 0 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **5. Análise dos Resultados e Comparação:**"
      ],
      "metadata": {
        "id": "v16jsGH5jlWm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora temos dois modelos treinados em exatamente a mesma tarefa, mas usando representações de texto diferentes. Compare os seguintes aspectos:  \n",
        "\n",
        "- **Acurácia (ou outra métrica de desempenho):** Qual modelo performou melhor no conjunto de teste? O uso de embeddings melhorou a performance? Em muitos casos, o modelo com embeddings pode ter performance igual ou superior ao BoW, especialmente se o dataset de treinamento for razoavelmente grande, pois o modelo consegue generalizar melhor para combinações de palavras que não viu explicitamente juntas no treino.  \n",
        "- **Tamanho das entradas e eficiência:** O modelo BoW tinha entrada de dimensão 5000 para cada texto. Já o modelo com embedding lida internamente com vetores de tamanho 50 (depois da média). Isso significa que o modelo com embedding tem bem menos neurônios na primeira camada densa efetiva (50->16 vs 5000->16), potencialmente necessitando de menos dados para treinar eficientemente. De fato, a primeira camada do modelo BoW (Dense com input 5000 e 16 neurônios) tinha 5000*16 = 80 mil pesos só aí, enquanto no modelo com embedding, a camada densa tem apenas 50*16 = 800 pesos (mas lembre que a camada de embedding tem 250k, então no total o modelo com embedding tem mais parâmetros distribuídos de forma diferente).  \n",
        "- **Capacidade de generalização:** Tente pensar em exemplos de frases que não estavam no conjunto de treino. Qual modelo teria mais chance de classificá-las corretamente? Provavelmente o modelo com embeddings, pois ele pode inferir pelo significado das palavras. Por exemplo, se nunca viu a palavra \"fantástico\" durante o treino mas viu \"excelente\" e \"maravilhoso\", o modelo com embedding pode ter posicionado \"fantástico\" próximo dessas outras palavras no espaço vetorial (talvez via inicialização ou por aparecer no texto de alguma forma), enquanto o BoW trataria \"fantástico\" como completamente nova (só zeros e um 1 numa nova coluna).  \n",
        "\n",
        "**Limitações dos Embeddings Simples:** É válido notar que, embora os embeddings melhorem a representação de palavras, o nosso modelo ainda é relativamente simples em termos de capturar contexto da frase. Usamos uma média dos embeddings, o que perde informação sobre ordem. Por exemplo, \"*não gostei*\" e \"*gostei muito*\" podem acabar com médias semelhantes de embeddings, confundindo o modelo. Técnicas mais avançadas, como redes recorrentes (RNN/LSTM), CNNs 1D ou Transformers (como BERT), são capazes de olhar a sequência de palavras inteira e aprender dependências mais complexas. Entretanto, essas técnicas têm custo computacional maior e fogem do escopo deste laboratório.  \n",
        "\n",
        "Para um começo, entender BoW vs Embedding já fornece uma ótima base: você viu na prática a diferença entre **contar palavras isoladas** e **aprender representações das palavras**.  \n"
      ],
      "metadata": {
        "id": "SK6BYFaSjmxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recapitulando"
      ],
      "metadata": {
        "id": "SsnE1YefjpXR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Bag-of-Words:** representação esparsa de alta dimensão, simples de obter, mas limitada por não capturar contexto ou similaridades semânticas entre palavras.  \n",
        "- **Word Embedding:** representação densa de baixa dimensão, que carrega relações semânticas (palavras semelhantes têm representações próximas). Necessita aprender os vetores de embedding, mas resulta em um modelo potencialmente mais generalizável.  \n",
        "\n",
        "Ambos os modelos que treinamos eram um **MLP** similar, a principal diferença foi na entrada (representação do texto). Ao comparar, devemos observar que *qualidade da representação de dados* muitas vezes é tão importante quanto o *modelo em si* em tarefas de aprendizado de máquina.  \n",
        "\n",
        "A **visualização de embeddings** é uma maneira poderosa de compreender como as palavras estão dispostas em um espaço vetorial depois do treinamento. A ideia é: após o modelo aprender (ou inicializar) os embeddings, pegamos os vetores de algumas palavras e projetamos esses vetores para 2D, de modo a gerar um gráfico que mostre a proximidade (ou distância) entre as palavras escolhidas.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "zZPJrR77js8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizando as representações das palavras no espaço"
      ],
      "metadata": {
        "id": "1aEcFVHhj3XB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Após o treinamento de sua rede com camada de embedding, escolha de 5 a 10 palavras do vocabulário (preferencialmente palavras que você considere interessantes ou relevantes para o domínio do dataset). Em seguida, extraia os vetores de embedding dessas palavras e aplique um método de redução de dimensionalidade (por exemplo, *PCA* ou *t-SNE*) para projetar esses vetores em 2D.  \n",
        "\n",
        "1. Faça um *scatter plot* (diagrama de dispersão) desses pontos em 2D usando, por exemplo, o `matplotlib`.  \n",
        "2. Rotule cada ponto com a palavra correspondente.  \n",
        "3. Comente se, de acordo com sua intuição sobre essas palavras, o embedding conseguiu ou não agrupar palavras semelhantes.\n",
        "\n",
        "*Dica:* Escolha palavras que apareçam com frequência suficiente no seu dataset para que o modelo possa ter **aprendido** algo sobre elas (palavras raras podem não ter sido bem ajustadas)."
      ],
      "metadata": {
        "id": "zzvwKsQLj7gJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Roteiro para visualização das palavras"
      ],
      "metadata": {
        "id": "TZdyPtHykDeN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Abaixo segue um roteiro simplificado para visualizar as plavras. Suponha que você já tenha:\n",
        "\n",
        "1. Um modelo `model_emb` com uma camada Embedding (treinada ou pelo menos inicializada).  \n",
        "2. Um `tokenizer` que mapeia cada palavra para um índice.  \n",
        "3. Uma lista de palavras que deseja visualizar.\n"
      ],
      "metadata": {
        "id": "weuX4fg7kCcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Extraindo vetores de embedding do modelo**"
      ],
      "metadata": {
        "id": "-oaDqWhQkJHt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primeiro, precisamos recuperar a matriz de pesos da camada de embedding que foi treinada. Essa camada geralmente é a primeira do modelo, algo como:"
      ],
      "metadata": {
        "id": "HttmGFNWkLm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = model_emb.layers[0]  # se a camada de Embedding for a primeira\n",
        "embedding_weights = embedding_layer.get_weights()[0]"
      ],
      "metadata": {
        "id": "ykHBQOVvjmTl"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `embedding_weights` terá o formato `(vocab_size, embedding_dim)`.  \n",
        "- Cada linha `i` desse array corresponde ao vetor de embedding da palavra cujo índice é `i`."
      ],
      "metadata": {
        "id": "EAxs-H_gkQVZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Definindo as palavras de interesse**"
      ],
      "metadata": {
        "id": "smiWUkItkS4b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Escolha manualmente algumas palavras que você sabe que estão presentes no vocabulário. Por exemplo, se você treina um classificador de resenhas de filmes, talvez escolha palavras como *\"filme\"*, *\"excelente\"*, *\"horrível\"*, *\"engraçado\"*, *\"ótimo\"*, *\"maravilhoso\"*, *\"medíocre\"* etc.\n",
        "\n",
        "Você pode verificar se elas estão no vocabulário do `tokenizer`:\n"
      ],
      "metadata": {
        "id": "Zo2VT52CkV3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chosen_words = [\"filme\", \"excelente\", \"horrível\", \"engraçado\", \"ótimo\", \"ruim\", \"bom\", \"adorei\"]"
      ],
      "metadata": {
        "id": "1TsIlIxGkYAh"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observação**: Se alguma palavra não estiver no vocabulário ou estiver fora do `num_words` definido no `Tokenizer`, ela poderá ser mapeada para o *OOV token* (`<OOV>`). Para evitar problemas, vamos verificar o índice de cada palavra:"
      ],
      "metadata": {
        "id": "UtGT9qd0kZir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index  # dicionário {palavra -> índice}\n",
        "# Se você definiu 'num_words=5000', alguns índices acima desse valor não são usados.\n",
        "# Precisamos nos certificar de pegar somente índices < max_words.\n",
        "\n",
        "valid_chosen_words = []\n",
        "for w in chosen_words:\n",
        "    if w in word_index and word_index[w] < embedding_weights.shape[0]:\n",
        "        valid_chosen_words.append(w)\n",
        "\n",
        "print(\"Palavras válidas no vocabulário:\", valid_chosen_words)"
      ],
      "metadata": {
        "id": "9RmpbT7Ikdnv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8c81438-0161-45d6-80fa-036125f9eb8b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palavras válidas no vocabulário: ['filme', 'excelente', 'horrível', 'engraçado', 'ótimo', 'ruim', 'bom', 'adorei']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`valid_chosen_words` conterá só as palavras que realmente têm embedding aprendido.  "
      ],
      "metadata": {
        "id": "2Pl-0jeIkhC2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Recuperar os vetores de embedding dessas palavras**"
      ],
      "metadata": {
        "id": "TaSYWiNNkg8z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para cada palavra válida, pegue seu índice e extraia o vetor de embedding:"
      ],
      "metadata": {
        "id": "y94_HcZcklJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectors = []\n",
        "labels = []\n",
        "\n",
        "for w in valid_chosen_words:\n",
        "    idx = word_index[w]  # índice no tokenizer\n",
        "    emb_vector = embedding_weights[idx]\n",
        "    vectors.append(emb_vector)\n",
        "    labels.append(w)\n",
        "\n",
        "vectors = np.array(vectors)  # shape: (n_palavras_escolhidas, embedding_dim)"
      ],
      "metadata": {
        "id": "LzyPs1g1klq9"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Redução de Dimensionalidade (PCA ou t-SNE)**"
      ],
      "metadata": {
        "id": "6TvFBAsGkopR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos usar **PCA** (mais rápido e simples) ou **t-SNE** (costuma gerar separações mais visíveis, mas é mais pesado e sensível a parâmetros). Abaixo vai um exemplo com PCA:"
      ],
      "metadata": {
        "id": "84ONTLb9krLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=2)\n",
        "vectors_2d = pca.fit_transform(vectors)  # shape: (n_palavras_escolhidas, 2)"
      ],
      "metadata": {
        "id": "WwQcUEsBkrvT"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se preferir **t-SNE**, ficaria algo como:"
      ],
      "metadata": {
        "id": "U_RnECP6ktq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tsne = TSNE(n_components=2, perplexity=5, learning_rate='auto')\n",
        "vectors_2d = tsne.fit_transform(vectors)"
      ],
      "metadata": {
        "id": "ZJE-Sxqqkuxb"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste exemplo, PCA deve ser suficiente."
      ],
      "metadata": {
        "id": "aDuGACAOkwJL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. Plotar em 2D com Matplotlib**"
      ],
      "metadata": {
        "id": "83mqq8Q2ky-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, desenhamos um scatter plot marcando cada ponto no plano 2D e rotulando com o texto da palavra:"
      ],
      "metadata": {
        "id": "CQAnm9ABk1IE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(vectors_2d[:, 0], vectors_2d[:, 1])\n",
        "\n",
        "for i, label in enumerate(labels):\n",
        "    x, y = vectors_2d[i, 0], vectors_2d[i, 1]\n",
        "    plt.text(x+0.01, y+0.01, label)  # um deslocamento pequeno p/ não sobrepor o ponto\n",
        "\n",
        "plt.title(\"Projeção 2D das Word Embeddings\")\n",
        "plt.xlabel(\"Componente PCA 1\")\n",
        "plt.ylabel(\"Componente PCA 2\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oGvV9rZlk3DA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "7aa50f92-ed4f-4b87-a2ca-c8f136cdfa19"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observe no gráfico se as palavras que você considera semanticamente próximas aparecem agrupadas. Se você treinou o embedding por pouco tempo ou em um dataset muito pequeno, a organização pode não ser tão clara. Em um conjunto de dados maior e após treino suficiente, é comum ver, por exemplo, palavras de conotação positiva mais próximas entre si, e as negativas agrupadas em outro canto.\n"
      ],
      "metadata": {
        "id": "dBPqwz1Hk42N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testando outras coisas (100pt)"
      ],
      "metadata": {
        "id": "zVIsBffPk9Dg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Você pode tentar **ajustar hiperparâmetros** e ver o efeito: por exemplo, mudar o tamanho do vocabulário (`max_features`), a dimensão do embedding (`output_dim`), o tamanho das camadas densas, ou o número de épocas de treinamento.  \n",
        "- Teste também remover **stopwords** (palavras muito comuns como \"de\", \"o\", \"a\", \"é\", que às vezes atrapalham). O `CountVectorizer` e o `Tokenizer` permitem facilmente filtrar stopwords (no CountVectorizer usamos `stop_words='portuguese'` se quisermos). Veja se isso melhora algo.  \n",
        "- Experimente outras formas de combinar embeddings de palavras para representar a frase: em vez de média, poderíamos usar máxima, ou até mesmo concatenar (via Flatten) e deixar a rede tentar extrair os padrões – embora isso aumente a dimensionalidade e possivelmente a necessidade de dados.  \n",
        "- Tente usar a camada Flatten ao invés de GlobalAveragePooling apos a camada de word embedding"
      ],
      "metadata": {
        "id": "cwOsLuyjk-rv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregando os dados novamente"
      ],
      "metadata": {
        "id": "GttfhojUmqWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separa colunas de texto e rótulos\n",
        "texts = df['text_pt'].values\n",
        "# Convert labels to numerical values (0 for 'neg', 1 for 'pos')\n",
        "labels = df['sentiment'].map({'neg': 0, 'pos': 1}).values"
      ],
      "metadata": {
        "id": "-VqezP-0mpGL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parte 1 - *Bag-of-Words* + MLP (35pt)"
      ],
      "metadata": {
        "id": "YhhdF2Lflnt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_words = set()\n",
        "for text in texts:\n",
        "    t = text.split()\n",
        "    unique_words.update(t)\n",
        "\n",
        "print(len(unique_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_DxzMoxGYYI",
        "outputId": "7f5c165a-0c30-46e8-b6ee-6f29395aa346"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "348285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# PARTE 1: Bag-of-Words + MLP\n",
        "# ============================================\n",
        "\n",
        "# 1) Vetorização Bag-of-Words\n",
        "max_features = 10_000\n",
        "vectorizer = CountVectorizer(max_features=max_features)\n",
        "\n",
        "X_bow = vectorizer.fit_transform(texts)"
      ],
      "metadata": {
        "id": "yb2RGPo2GRFB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Dividir em treino e teste\n",
        "X_train_bow, X_test_bow, y_train, y_test = train_test_split(\n",
        "    X_bow, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Conjunto de treino - textos:\", X_train_bow.shape, \" rótulos:\", y_train.shape)\n",
        "print(\"Conjunto de teste - textos:\", X_test_bow.shape, \" rótulos:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AG-cJO-PIPO6",
        "outputId": "ef13b71a-1b0f-4fa8-deb9-2dbdc14edf2f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conjunto de treino - textos: (39567, 10000)  rótulos: (39567,)\n",
            "Conjunto de teste - textos: (9892, 10000)  rótulos: (9892,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Definir e montar o modelo MLP\n",
        "model_bow = Sequential([\n",
        "    InputLayer(shape=(X_train_bow.shape[1],)),\n",
        "    Dense(512, activation = 'relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation = 'gelu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation = 'swish'),\n",
        "    Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "model_bow.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_bow.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "Ykj51w72IcUT",
        "outputId": "dc27d172-d832-478d-c100-99b2a9f6a09e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │       \u001b[38;5;34m5,120,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m65,664\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m4,128\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,190,337\u001b[0m (19.80 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,190,337</span> (19.80 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,190,337\u001b[0m (19.80 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,190,337</span> (19.80 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Treinar (convertemos a matriz esparsa em densa com toarray())\n",
        "history_bow = model_bow.fit(X_train_bow.toarray(),\n",
        "                            np.asarray([0 if x == 'neg' else 1 for x in y_train]),  # convertendo X_train de esparso para denso para treinar\n",
        "                            epochs=5,\n",
        "                            batch_size=32,\n",
        "                            validation_data=(X_test_bow.toarray(), y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K973arHpJUD6",
        "outputId": "1618c80a-b24a-4461-b0c8-96ed7e63b0ef"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9956 - loss: 0.0588 - val_accuracy: 0.4907 - val_loss: 9.7749\n",
            "Epoch 2/5\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.4907 - val_loss: 12.0862\n",
            "Epoch 3/5\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.4907 - val_loss: 13.5961\n",
            "Epoch 4/5\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.9862e-04 - val_accuracy: 0.4907 - val_loss: 14.7187\n",
            "Epoch 5/5\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.3492e-04 - val_accuracy: 0.4907 - val_loss: 15.6211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) Avaliar\n",
        "loss_bow, acc_bow = model_bow.evaluate(X_test_bow.toarray(), y_test, verbose=0)\n",
        "print(f\"Acurácia no conjunto de teste (BoW + MLP): {acc_bow:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0v-aecQvKpzc",
        "outputId": "d0c8d84c-d5f1-4f10-99b1-7a7639ca9b90"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia no conjunto de teste (BoW + MLP): 0.4907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parte 2 - *Word Embeddings* + MLP (35pt)"
      ],
      "metadata": {
        "id": "P28vlJmQmjTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# PARTE 2: Word Embeddings + MLP\n",
        "# ============================================\n",
        "\n",
        "# 1) Tokenizar e transformar em sequências\n",
        "\n",
        "max_words = 10_000\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "maxlen = 150\n",
        "X_seq = pad_sequences(sequences, maxlen=maxlen, padding='post', truncating='post')"
      ],
      "metadata": {
        "id": "6zVtKFPKK3wA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Dividir em treino e teste\n",
        "X_train_seq, X_test_seq, y_train_seq, y_test_seq = train_test_split(\n",
        "    X_seq, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Treino seq shape:\", X_train_seq.shape, \"Teste seq shape:\", X_test_seq.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TftH4O1LaZT",
        "outputId": "e44302d2-8066-4443-c8f6-ee61be9327bf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treino seq shape: (39567, 150) Teste seq shape: (9892, 150)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Construir o modelo com camada de Embedding\n",
        "embedding_dim = 150\n",
        "model_emb = Sequential([\n",
        "    InputLayer(shape=(X_train_seq.shape[1],)),\n",
        "    Embedding(input_dim=max_words,\n",
        "              output_dim=embedding_dim,\n",
        "              input_length=maxlen),\n",
        "    GlobalAveragePooling1D(),\n",
        "    Dense(64, activation = \"relu\"),\n",
        "    Dense(8, activation = \"relu\"),\n",
        "    Dense(1, activation = \"sigmoid\"),\n",
        "])\n",
        "\n",
        "model_emb.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_emb.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "3on4qEqBLjQz",
        "outputId": "d0843ad5-5821-4b67-e849-1a583a106e8a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_7 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m1,500,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m9,664\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m520\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m9\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,500,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,664</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,510,193\u001b[0m (5.76 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,510,193</span> (5.76 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,510,193\u001b[0m (5.76 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,510,193</span> (5.76 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Treinar\n",
        "history_emb = model_emb.fit(X_train_seq,\n",
        "                            y_train_seq,\n",
        "                            epochs=10,\n",
        "                            batch_size=32,\n",
        "                            validation_data=(X_test_seq, y_test_seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtAJ_zoLMSrQ",
        "outputId": "ed6ed4a6-8c90-4763-bac0-c9c2e63d6061"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.7384 - loss: 0.5071 - val_accuracy: 0.8474 - val_loss: 0.3489\n",
            "Epoch 2/10\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8791 - loss: 0.2925 - val_accuracy: 0.8559 - val_loss: 0.3420\n",
            "Epoch 3/10\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8976 - loss: 0.2491 - val_accuracy: 0.8223 - val_loss: 0.4258\n",
            "Epoch 4/10\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9114 - loss: 0.2254 - val_accuracy: 0.8438 - val_loss: 0.3728\n",
            "Epoch 5/10\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9169 - loss: 0.2095 - val_accuracy: 0.8480 - val_loss: 0.4032\n",
            "Epoch 6/10\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9267 - loss: 0.1788 - val_accuracy: 0.8447 - val_loss: 0.4142\n",
            "Epoch 7/10\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9357 - loss: 0.1496 - val_accuracy: 0.8376 - val_loss: 0.4792\n",
            "Epoch 8/10\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9445 - loss: 0.1270 - val_accuracy: 0.8359 - val_loss: 0.6089\n",
            "Epoch 9/10\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9513 - loss: 0.1052 - val_accuracy: 0.8314 - val_loss: 0.6566\n",
            "Epoch 10/10\n",
            "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9590 - loss: 0.0890 - val_accuracy: 0.8335 - val_loss: 0.7704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) Avaliar\n",
        "loss_emb, acc_emb = model_emb.evaluate(X_test_seq, y_test_seq, verbose=0)\n",
        "print(f\"Acurácia no conjunto de teste (Embeddings + MLP): {acc_emb:.4f}\")\n"
      ],
      "metadata": {
        "id": "lZSNsLsomidP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a77760fe-4b2d-4d3d-f4bb-b388f2c4fcdd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia no conjunto de teste (Embeddings + MLP): 0.8335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parte 3 - Visualizando as representações criadas (30 pt)"
      ],
      "metadata": {
        "id": "G0nkWGUZnJPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# PARTE 3: Visualização das embeddings criadas\n",
        "# ============================================\n",
        "\n",
        "# 1) Pegar os embeddings do modelo treinado\n",
        "embedding_layer = model_emb.layers[0]\n",
        "embedding_weights = embedding_layer.get_weights()[0]\n",
        "\n",
        "\n",
        "# 2) Escolher as palavras para avaliar\n",
        "# ToDo\n",
        "#   - Sugestão de palavras (escolha mais)\n",
        "#       - filme        - amei\n",
        "#       - excelente    - ótimo\n",
        "#       - bom          - horrível\n",
        "#       - engraçado    - beleza\n",
        "#       - estranho     - agradável\n",
        "#       - avassalador  - ruim\n",
        "#       - medonho      - terrível\n",
        "#       - bom          - adorei\n",
        "\n",
        "chosen_words = [\"excelente\", \"incrível\", \"terrível\", \"horroroso\", \"excepcional\", \"péssimo\", \"bom\", \"ruim\", \"legal\", \"chato\"]\n",
        "\n",
        "# 3) Certificar de pegar somente as palavras válidas\n",
        "word_index = tokenizer.word_index\n",
        "valid_chosen_words = []\n",
        "for w in chosen_words:\n",
        "    if w in word_index and word_index[w] < embedding_weights.shape[0]:\n",
        "        valid_chosen_words.append(w)\n",
        "print(\"Palavras válidas no vocabulário:\", valid_chosen_words)\n",
        "print(\"palavras não presentes no vocabulário:\", set(chosen_words) - set(valid_chosen_words))\n",
        "\n",
        "# 4) Gerar as embeddings e os labels correspondentes para cada palavra\n",
        "vectors = []\n",
        "labels = []\n",
        "for w in valid_chosen_words:\n",
        "    idx = word_index[w]\n",
        "    emb_vector = embedding_weights[idx]\n",
        "    vectors.append(emb_vector)\n",
        "    labels.append(w)\n",
        "\n",
        "vectors = np.array(vectors)\n",
        "\n",
        "# 5) Reduzir a dimensionalidade das embeddings para somente duas dimensões\n",
        "tsne = TSNE(n_components=2, perplexity=5, learning_rate='auto')\n",
        "vectors_2d = tsne.fit_transform(vectors)\n",
        "\n",
        "# 6) Plotar as palavras escolhidas\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(vectors_2d[:, 0], vectors_2d[:, 1])\n",
        "\n",
        "for i, label in enumerate(labels):\n",
        "    x, y = vectors_2d[i, 0], vectors_2d[i, 1]\n",
        "    plt.text(x+0.01, y+0.01, label)\n",
        "\n",
        "plt.title(\"Projeção 2D das Word Embeddings\")\n",
        "plt.xlabel(\"Componente PCA 1\")\n",
        "plt.ylabel(\"Componente PCA 2\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4r_qURGznTKL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "outputId": "cdf71ebf-d432-4b4a-a675-145d278149b6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palavras válidas no vocabulário: ['excelente', 'incrível', 'terrível', 'excepcional', 'péssimo', 'bom', 'ruim', 'legal', 'chato']\n",
            "palavras não presentes no vocabulário: {'horroroso'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}